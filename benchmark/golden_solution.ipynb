{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Golden Solution: Research Paper Entity Extraction and Citation Analysis\n",
    "\n",
    "This notebook contains the **reference implementation** for the benchmark task.\n",
    "It demonstrates that the task is solvable and provides the expected outputs.\n",
    "\n",
    "**Features:**\n",
    "- Self-contained dataset generation (no file uploads needed)\n",
    "- Runs end-to-end without manual intervention\n",
    "- Passes all unit tests\n",
    "\n",
    "**Note:** This is the golden solution - it should pass all unit tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install -q pandas networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Any, Tuple\n",
    "import re\n",
    "import networkx as nx\n",
    "import warnings\n",
    "import unittest\n",
    "import random\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Dataset\n",
    "\n",
    "Generate the synthetic benchmark dataset. This ensures the notebook is fully self-contained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DATASET GENERATION - Self-contained synthetic data generation\n",
    "# ============================================================================\n",
    "\n",
    "# Set seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Canonical authors with their name variations\n",
    "CANONICAL_AUTHORS = {\n",
    "    \"auth_001\": {\"canonical_name\": \"John Smith\", \"variations\": [\"J. Smith\", \"John A. Smith\", \"J. A. Smith\", \"Smith, John\"], \"institution\": \"inst_001\"},\n",
    "    \"auth_002\": {\"canonical_name\": \"Maria Garcia\", \"variations\": [\"M. Garcia\", \"Maria L. Garcia\", \"Garcia, Maria\", \"M. L. Garcia\"], \"institution\": \"inst_002\"},\n",
    "    \"auth_003\": {\"canonical_name\": \"Wei Zhang\", \"variations\": [\"W. Zhang\", \"Wei W. Zhang\", \"Zhang, Wei\", \"Zhang Wei\"], \"institution\": \"inst_003\"},\n",
    "    \"auth_004\": {\"canonical_name\": \"Emily Johnson\", \"variations\": [\"E. Johnson\", \"Emily R. Johnson\", \"Johnson, Emily\", \"E. R. Johnson\"], \"institution\": \"inst_001\"},\n",
    "    \"auth_005\": {\"canonical_name\": \"Ahmed Hassan\", \"variations\": [\"A. Hassan\", \"Ahmed M. Hassan\", \"Hassan, Ahmed\", \"A. M. Hassan\"], \"institution\": \"inst_004\"},\n",
    "    \"auth_006\": {\"canonical_name\": \"Sarah Williams\", \"variations\": [\"S. Williams\", \"Sarah K. Williams\", \"Williams, Sarah\", \"S. K. Williams\"], \"institution\": \"inst_002\"},\n",
    "    \"auth_007\": {\"canonical_name\": \"Yuki Tanaka\", \"variations\": [\"Y. Tanaka\", \"Yuki S. Tanaka\", \"Tanaka, Yuki\", \"Tanaka Yuki\"], \"institution\": \"inst_005\"},\n",
    "    \"auth_008\": {\"canonical_name\": \"Michael Brown\", \"variations\": [\"M. Brown\", \"Michael J. Brown\", \"Brown, Michael\", \"M. J. Brown\"], \"institution\": \"inst_003\"},\n",
    "    \"auth_009\": {\"canonical_name\": \"Lisa Chen\", \"variations\": [\"L. Chen\", \"Lisa Y. Chen\", \"Chen, Lisa\", \"Chen Lisa\"], \"institution\": \"inst_004\"},\n",
    "    \"auth_010\": {\"canonical_name\": \"David Miller\", \"variations\": [\"D. Miller\", \"David A. Miller\", \"Miller, David\", \"D. A. Miller\"], \"institution\": \"inst_005\"}\n",
    "}\n",
    "\n",
    "CANONICAL_INSTITUTIONS = {\n",
    "    \"inst_001\": {\"canonical_name\": \"Massachusetts Institute of Technology\", \"variations\": [\"MIT\", \"M.I.T.\", \"Massachusetts Inst. of Technology\"], \"country\": \"USA\"},\n",
    "    \"inst_002\": {\"canonical_name\": \"Stanford University\", \"variations\": [\"Stanford\", \"Stanford Univ.\", \"Stanford U.\"], \"country\": \"USA\"},\n",
    "    \"inst_003\": {\"canonical_name\": \"Tsinghua University\", \"variations\": [\"Tsinghua\", \"Tsinghua Univ.\", \"THU\"], \"country\": \"China\"},\n",
    "    \"inst_004\": {\"canonical_name\": \"University of Oxford\", \"variations\": [\"Oxford\", \"Oxford Univ.\", \"Univ. of Oxford\"], \"country\": \"UK\"},\n",
    "    \"inst_005\": {\"canonical_name\": \"University of Tokyo\", \"variations\": [\"Tokyo Univ.\", \"UTokyo\", \"Univ. of Tokyo\"], \"country\": \"Japan\"}\n",
    "}\n",
    "\n",
    "RESEARCH_TOPICS = [\"machine learning\", \"deep learning\", \"neural networks\", \"natural language processing\",\n",
    "    \"computer vision\", \"reinforcement learning\", \"transformer models\", \"attention mechanisms\",\n",
    "    \"graph neural networks\", \"federated learning\", \"transfer learning\", \"meta-learning\",\n",
    "    \"generative models\", \"adversarial learning\", \"explainable AI\", \"optimization\"]\n",
    "\n",
    "RESEARCH_METHODS = [\"gradient descent\", \"backpropagation\", \"stochastic optimization\", \"cross-validation\",\n",
    "    \"ablation study\", \"hyperparameter tuning\", \"ensemble methods\", \"regularization\",\n",
    "    \"dropout\", \"batch normalization\", \"attention mechanism\", \"skip connections\"]\n",
    "\n",
    "VENUES = [\"NeurIPS\", \"ICML\", \"ICLR\", \"AAAI\", \"CVPR\", \"ACL\", \"EMNLP\", \"KDD\", \"WWW\", \"IJCAI\"]\n",
    "\n",
    "def generate_papers(num_papers=100):\n",
    "    papers = []\n",
    "    author_ids = list(CANONICAL_AUTHORS.keys())\n",
    "    base_date = datetime(2020, 1, 1)\n",
    "    \n",
    "    for i in range(num_papers):\n",
    "        paper_id = f\"paper_{i:04d}\"\n",
    "        num_authors = random.randint(1, 4)\n",
    "        selected_author_ids = random.sample(author_ids, num_authors)\n",
    "        \n",
    "        authors = []\n",
    "        for aid in selected_author_ids:\n",
    "            auth = CANONICAL_AUTHORS[aid]\n",
    "            if random.random() > 0.4:\n",
    "                authors.append(random.choice(auth[\"variations\"]))\n",
    "            else:\n",
    "                authors.append(auth[\"canonical_name\"])\n",
    "        \n",
    "        primary_inst_id = CANONICAL_AUTHORS[selected_author_ids[0]][\"institution\"]\n",
    "        inst = CANONICAL_INSTITUTIONS[primary_inst_id]\n",
    "        institution = random.choice(inst[\"variations\"]) if random.random() > 0.5 else inst[\"canonical_name\"]\n",
    "        \n",
    "        paper_topics = random.sample(RESEARCH_TOPICS, random.randint(2, 4))\n",
    "        abstract = f\"This paper presents research on {paper_topics[0]} using {random.choice(RESEARCH_METHODS)}.\"\n",
    "        \n",
    "        paper = {\n",
    "            \"paper_id\": paper_id, \"title\": f\"Research on {paper_topics[0].title()}\",\n",
    "            \"authors\": authors, \"institution\": institution, \"abstract\": abstract,\n",
    "            \"keywords\": paper_topics, \"venue\": random.choice(VENUES),\n",
    "            \"year\": (base_date + timedelta(days=random.randint(0, 1500))).year,\n",
    "            \"publication_date\": (base_date + timedelta(days=random.randint(0, 1500))).strftime(\"%Y-%m-%d\"),\n",
    "        }\n",
    "        \n",
    "        # Edge cases\n",
    "        if i == 5: paper[\"abstract\"] = \"\"\n",
    "        if i == 12: paper[\"keywords\"] = []\n",
    "        if i == 45: paper[\"institution\"] = None\n",
    "        if i == 67: paper[\"authors\"].append(CANONICAL_AUTHORS[selected_author_ids[0]][\"variations\"][0])\n",
    "        \n",
    "        papers.append(paper)\n",
    "    return papers\n",
    "\n",
    "def generate_citations(papers, density=0.05):\n",
    "    citations = []\n",
    "    paper_ids = [p[\"paper_id\"] for p in papers]\n",
    "    paper_years = {p[\"paper_id\"]: p[\"year\"] for p in papers}\n",
    "    \n",
    "    for citing_paper in paper_ids:\n",
    "        citing_year = paper_years[citing_paper]\n",
    "        citable = [p for p in paper_ids if paper_years[p] <= citing_year and p != citing_paper]\n",
    "        if citable:\n",
    "            num_citations = min(max(1, int(len(citable) * density * random.uniform(0.5, 1.5))), len(citable), 10)\n",
    "            for cited in random.sample(citable, num_citations):\n",
    "                citations.append({\"citing_paper\": citing_paper, \"cited_paper\": cited})\n",
    "    \n",
    "    citations.append({\"citing_paper\": \"paper_0010\", \"cited_paper\": \"paper_9999\"})  # Orphan\n",
    "    citations.append({\"citing_paper\": \"paper_0015\", \"cited_paper\": \"paper_0015\"})  # Self-citation\n",
    "    return citations\n",
    "\n",
    "def generate_author_affiliations():\n",
    "    affiliations = {\"authors\": {}, \"institutions\": {}}\n",
    "    for auth_id, auth_data in CANONICAL_AUTHORS.items():\n",
    "        affiliations[\"authors\"][auth_id] = {\n",
    "            \"canonical_name\": auth_data[\"canonical_name\"],\n",
    "            \"known_variations\": auth_data[\"variations\"][:2],\n",
    "            \"primary_institution\": auth_data[\"institution\"],\n",
    "        }\n",
    "    for inst_id, inst_data in CANONICAL_INSTITUTIONS.items():\n",
    "        affiliations[\"institutions\"][inst_id] = {\n",
    "            \"canonical_name\": inst_data[\"canonical_name\"],\n",
    "            \"known_variations\": inst_data[\"variations\"][:2],\n",
    "            \"country\": inst_data[\"country\"]\n",
    "        }\n",
    "    return affiliations\n",
    "\n",
    "# Generate the dataset\n",
    "print(\"Generating synthetic dataset...\")\n",
    "papers_raw = generate_papers(100)\n",
    "citations_raw = pd.DataFrame(generate_citations(papers_raw))\n",
    "affiliations_raw = generate_author_affiliations()\n",
    "\n",
    "print(f\"✓ Papers: {len(papers_raw)}, Citations: {len(citations_raw)}, Authors: {len(affiliations_raw['authors'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Golden Solution Implementation\n",
    "\n",
    "The reference implementation for the benchmark task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# CORE DATA VARIABLES\n",
    "# ============================================================================\n",
    "\n",
    "papers_df = pd.DataFrame(papers_raw)\n",
    "citations_df = citations_raw.copy()\n",
    "affiliations_data = affiliations_raw.copy()\n",
    "\n",
    "print(f\"papers_df: {len(papers_df)} rows\")\n",
    "print(f\"citations_df: {len(citations_df)} rows\")\n",
    "print(f\"affiliations_data keys: {list(affiliations_data.keys())}\")\n",
    "\n",
    "# ============================================================================\n",
    "# ENTITY RESOLUTION MAPS\n",
    "# ============================================================================\n",
    "\n",
    "author_resolution_map = {}\n",
    "institution_resolution_map = {}\n",
    "\n",
    "# Build resolution maps from reference data\n",
    "for auth_id, auth_info in affiliations_data[\"authors\"].items():\n",
    "    canonical = auth_info[\"canonical_name\"]\n",
    "    author_resolution_map[canonical] = canonical\n",
    "    for var in auth_info.get(\"known_variations\", []):\n",
    "        author_resolution_map[var] = canonical\n",
    "\n",
    "for inst_id, inst_info in affiliations_data[\"institutions\"].items():\n",
    "    canonical = inst_info[\"canonical_name\"]\n",
    "    institution_resolution_map[canonical] = canonical\n",
    "    for var in inst_info.get(\"known_variations\", []):\n",
    "        institution_resolution_map[var] = canonical\n",
    "\n",
    "print(f\"Author resolution map: {len(author_resolution_map)} entries\")\n",
    "print(f\"Institution resolution map: {len(institution_resolution_map)} entries\")\n",
    "\n",
    "# ============================================================================\n",
    "# ENTITY EXTRACTION\n",
    "# ============================================================================\n",
    "\n",
    "extracted_authors_dict = defaultdict(lambda: {\"name\": \"\", \"paper_ids\": [], \"name_variations\": set()})\n",
    "extracted_institutions_dict = defaultdict(lambda: {\"name\": \"\", \"paper_ids\": [], \"name_variations\": set()})\n",
    "all_keywords = []\n",
    "methods_from_abstracts = []\n",
    "\n",
    "KNOWN_METHODS = [\"gradient descent\", \"backpropagation\", \"cross-validation\", \"ablation study\",\n",
    "                 \"attention mechanism\", \"dropout\", \"batch normalization\", \"pre-training\", \"fine-tuning\"]\n",
    "\n",
    "for _, row in papers_df.iterrows():\n",
    "    pid = row[\"paper_id\"]\n",
    "    \n",
    "    # Extract authors\n",
    "    authors = row[\"authors\"] if isinstance(row[\"authors\"], list) else []\n",
    "    for auth in authors:\n",
    "        resolved = author_resolution_map.get(auth, auth)\n",
    "        extracted_authors_dict[resolved][\"name\"] = resolved\n",
    "        extracted_authors_dict[resolved][\"paper_ids\"].append(pid)\n",
    "        extracted_authors_dict[resolved][\"name_variations\"].add(auth)\n",
    "    \n",
    "    # Extract institutions\n",
    "    inst = row.get(\"institution\")\n",
    "    if inst:\n",
    "        resolved_inst = institution_resolution_map.get(inst, inst)\n",
    "        extracted_institutions_dict[resolved_inst][\"name\"] = resolved_inst\n",
    "        extracted_institutions_dict[resolved_inst][\"paper_ids\"].append(pid)\n",
    "        extracted_institutions_dict[resolved_inst][\"name_variations\"].add(inst)\n",
    "    \n",
    "    # Extract topics\n",
    "    kws = row.get(\"keywords\", [])\n",
    "    if isinstance(kws, list):\n",
    "        all_keywords.extend(kws)\n",
    "    \n",
    "    # Extract methods from abstracts\n",
    "    abstract = row.get(\"abstract\", \"\")\n",
    "    if isinstance(abstract, str):\n",
    "        for method in KNOWN_METHODS:\n",
    "            if method.lower() in abstract.lower():\n",
    "                methods_from_abstracts.append(method)\n",
    "\n",
    "# Convert to required format\n",
    "extracted_authors = [{\"name\": v[\"name\"], \"paper_ids\": v[\"paper_ids\"], \"name_variations\": list(v[\"name_variations\"])} \n",
    "                     for v in extracted_authors_dict.values()]\n",
    "extracted_institutions = [{\"name\": v[\"name\"], \"paper_ids\": v[\"paper_ids\"], \"name_variations\": list(v[\"name_variations\"])} \n",
    "                          for v in extracted_institutions_dict.values()]\n",
    "extracted_topics = dict(Counter(all_keywords))\n",
    "methods_from_abstracts = list(set(methods_from_abstracts))\n",
    "\n",
    "resolved_author_count = len(extracted_authors)\n",
    "resolved_institution_count = len(extracted_institutions)\n",
    "\n",
    "print(f\"Extracted authors: {len(extracted_authors)}\")\n",
    "print(f\"Extracted institutions: {len(extracted_institutions)}\")\n",
    "print(f\"Extracted topics: {len(extracted_topics)}\")\n",
    "print(f\"Methods from abstracts: {len(methods_from_abstracts)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# CITATION NETWORK\n",
    "# ============================================================================\n",
    "\n",
    "valid_paper_ids = set(papers_df[\"paper_id\"].unique())\n",
    "\n",
    "citation_graph = defaultdict(list)\n",
    "in_degree = {pid: 0 for pid in valid_paper_ids}\n",
    "out_degree = {pid: 0 for pid in valid_paper_ids}\n",
    "orphan_citations = []\n",
    "self_citations = []\n",
    "\n",
    "for _, row in citations_df.iterrows():\n",
    "    src, dst = row[\"citing_paper\"], row[\"cited_paper\"]\n",
    "    \n",
    "    if src in valid_paper_ids:\n",
    "        citation_graph[src].append(dst)\n",
    "        out_degree[src] += 1\n",
    "    \n",
    "    if dst in valid_paper_ids:\n",
    "        in_degree[dst] += 1\n",
    "    \n",
    "    if dst not in valid_paper_ids:\n",
    "        orphan_citations.append({\"citing_paper\": src, \"cited_paper\": dst})\n",
    "    \n",
    "    if src == dst:\n",
    "        self_citations.append(src)\n",
    "\n",
    "self_citations = list(set(self_citations))\n",
    "citation_graph = dict(citation_graph)\n",
    "\n",
    "# PageRank computation\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(valid_paper_ids)\n",
    "for src, targets in citation_graph.items():\n",
    "    for dst in targets:\n",
    "        if dst in valid_paper_ids:\n",
    "            G.add_edge(src, dst)\n",
    "\n",
    "pagerank_scores = nx.pagerank(G, alpha=0.85, max_iter=100, tol=1e-6)\n",
    "\n",
    "# Top cited papers\n",
    "sorted_by_citations = sorted(in_degree.items(), key=lambda x: x[1], reverse=True)\n",
    "top_cited_papers = [x[0] for x in sorted_by_citations[:10]]\n",
    "\n",
    "print(f\"Citation graph nodes: {len(citation_graph)}\")\n",
    "print(f\"Orphan citations: {len(orphan_citations)}\")\n",
    "print(f\"Self citations: {len(self_citations)}\")\n",
    "print(f\"PageRank sum: {sum(pagerank_scores.values()):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VALIDATION AND SUMMARY STATISTICS\n",
    "# ============================================================================\n",
    "\n",
    "# Count unique authors/institutions before resolution\n",
    "unique_authors_raw = set()\n",
    "for authors in papers_df[\"authors\"]:\n",
    "    if isinstance(authors, list):\n",
    "        unique_authors_raw.update(authors)\n",
    "\n",
    "unique_institutions_raw = set(papers_df[\"institution\"].dropna().unique())\n",
    "\n",
    "# Summary statistics\n",
    "summary_stats = {\n",
    "    \"total_papers\": len(papers_df),\n",
    "    \"total_citations\": len(citations_df),\n",
    "    \"unique_authors_raw\": len(unique_authors_raw),\n",
    "    \"unique_authors_resolved\": resolved_author_count,\n",
    "    \"unique_institutions_raw\": len(unique_institutions_raw),\n",
    "    \"unique_institutions_resolved\": resolved_institution_count,\n",
    "    \"papers_with_missing_abstract\": int((papers_df[\"abstract\"] == \"\").sum() + papers_df[\"abstract\"].isna().sum()),\n",
    "    \"papers_with_missing_keywords\": int(sum(1 for kw in papers_df[\"keywords\"] if not isinstance(kw, list) or len(kw) == 0)),\n",
    "    \"orphan_citation_count\": len(orphan_citations),\n",
    "    \"self_citation_count\": len(self_citations),\n",
    "    \"avg_citations_per_paper\": len(citations_df) / len(papers_df) if len(papers_df) > 0 else 0,\n",
    "    \"most_common_venue\": papers_df[\"venue\"].mode()[0] if not papers_df[\"venue\"].empty else None,\n",
    "    \"year_range\": (int(papers_df[\"year\"].min()), int(papers_df[\"year\"].max()))\n",
    "}\n",
    "\n",
    "# Validation results\n",
    "validation_results = {\n",
    "    \"papers_loaded_ok\": len(papers_df) > 0 and all(col in papers_df.columns for col in [\"paper_id\", \"title\", \"authors\"]),\n",
    "    \"citations_loaded_ok\": len(citations_df) > 0 and all(col in citations_df.columns for col in [\"citing_paper\", \"cited_paper\"]),\n",
    "    \"affiliations_loaded_ok\": isinstance(affiliations_data, dict) and \"authors\" in affiliations_data and \"institutions\" in affiliations_data,\n",
    "    \"no_duplicate_paper_ids\": papers_df[\"paper_id\"].is_unique,\n",
    "    \"authors_extracted\": len(extracted_authors) > 0,\n",
    "    \"institutions_extracted\": len(extracted_institutions) > 0,\n",
    "    \"resolution_maps_valid\": len(author_resolution_map) > 0 and len(institution_resolution_map) > 0,\n",
    "    \"citation_graph_built\": len(citation_graph) > 0,\n",
    "    \"pagerank_computed\": len(pagerank_scores) > 0 and len(pagerank_scores) == len(papers_df),\n",
    "    \"orphans_identified\": True,  # We checked for orphans\n",
    "    \"self_citations_identified\": True,  # We checked for self-citations\n",
    "    \"all_pagerank_finite\": all(np.isfinite(v) for v in pagerank_scores.values())\n",
    "}\n",
    "\n",
    "print(\"Summary Statistics:\")\n",
    "for k, v in summary_stats.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(\"\\nValidation Results:\")\n",
    "for k, v in validation_results.items():\n",
    "    print(f\"  {k}: {'✓' if v else '✗'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# FINAL REPORT\n",
    "# ============================================================================\n",
    "\n",
    "# Top authors by paper count\n",
    "author_paper_counts = [(a[\"name\"], len(a[\"paper_ids\"])) for a in extracted_authors]\n",
    "top_5_authors = sorted(author_paper_counts, key=lambda x: x[1], reverse=True)[:5]\n",
    "\n",
    "# Top institutions by paper count\n",
    "inst_paper_counts = [(i[\"name\"], len(i[\"paper_ids\"])) for i in extracted_institutions]\n",
    "top_5_institutions = sorted(inst_paper_counts, key=lambda x: x[1], reverse=True)[:5]\n",
    "\n",
    "# Top topics\n",
    "top_10_topics = sorted(extracted_topics.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "# Top cited papers with titles\n",
    "top_10_cited_papers = []\n",
    "for pid in top_cited_papers:\n",
    "    paper_row = papers_df[papers_df[\"paper_id\"] == pid]\n",
    "    if not paper_row.empty:\n",
    "        top_10_cited_papers.append({\n",
    "            \"paper_id\": pid,\n",
    "            \"citation_count\": in_degree[pid],\n",
    "            \"title\": paper_row[\"title\"].values[0]\n",
    "        })\n",
    "\n",
    "final_report = {\n",
    "    \"metadata\": {\n",
    "        \"task\": \"Research Paper Entity Extraction and Citation Analysis\",\n",
    "        \"papers_analyzed\": len(papers_df),\n",
    "        \"execution_timestamp\": datetime.now().isoformat()\n",
    "    },\n",
    "    \"entity_extraction\": {\n",
    "        \"authors\": {\n",
    "            \"total_unique\": resolved_author_count,\n",
    "            \"top_5_by_paper_count\": [{\"name\": n, \"paper_count\": c} for n, c in top_5_authors]\n",
    "        },\n",
    "        \"institutions\": {\n",
    "            \"total_unique\": resolved_institution_count,\n",
    "            \"top_5_by_paper_count\": [{\"name\": n, \"paper_count\": c} for n, c in top_5_institutions]\n",
    "        },\n",
    "        \"topics\": {\n",
    "            \"total_unique\": len(extracted_topics),\n",
    "            \"top_10_by_frequency\": [{\"topic\": t, \"count\": c} for t, c in top_10_topics]\n",
    "        }\n",
    "    },\n",
    "    \"citation_analysis\": {\n",
    "        \"total_citations\": len(citations_df),\n",
    "        \"top_10_cited_papers\": top_10_cited_papers,\n",
    "        \"orphan_citations\": orphan_citations,\n",
    "        \"self_citations\": self_citations,\n",
    "        \"network_statistics\": {\n",
    "            \"avg_in_degree\": np.mean(list(in_degree.values())),\n",
    "            \"avg_out_degree\": np.mean(list(out_degree.values())),\n",
    "            \"max_in_degree\": max(in_degree.values()),\n",
    "            \"max_out_degree\": max(out_degree.values())\n",
    "        }\n",
    "    },\n",
    "    \"data_quality\": {\n",
    "        \"missing_abstracts\": summary_stats[\"papers_with_missing_abstract\"],\n",
    "        \"missing_keywords\": summary_stats[\"papers_with_missing_keywords\"],\n",
    "        \"missing_institutions\": int(papers_df[\"institution\"].isna().sum()),\n",
    "        \"duplicate_author_entries\": len(unique_authors_raw) - resolved_author_count\n",
    "    },\n",
    "    \"validation_summary\": {\n",
    "        \"all_checks_passed\": all(validation_results.values()),\n",
    "        \"failed_checks\": [k for k, v in validation_results.items() if not v]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"=== VALIDATION RESULTS ===\")\n",
    "print(json.dumps(validation_results, indent=2))\n",
    "print(\"\\n=== FINAL REPORT ===\")\n",
    "print(json.dumps(final_report, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---\n",
    "\n",
    "# Unit Tests\n",
    "\n",
    "Comprehensive tests to validate the golden solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class TestDataLoading(unittest.TestCase):\n",
    "    def test_papers_df_exists(self):\n",
    "        self.assertIsInstance(papers_df, pd.DataFrame)\n",
    "        self.assertGreater(len(papers_df), 0)\n",
    "    \n",
    "    def test_papers_df_columns(self):\n",
    "        required = {'paper_id', 'title', 'authors', 'institution', 'abstract', 'keywords', 'venue', 'year'}\n",
    "        self.assertTrue(required.issubset(set(papers_df.columns)))\n",
    "    \n",
    "    def test_citations_df_exists(self):\n",
    "        self.assertIsInstance(citations_df, pd.DataFrame)\n",
    "        self.assertGreater(len(citations_df), 0)\n",
    "    \n",
    "    def test_affiliations_structure(self):\n",
    "        self.assertIsInstance(affiliations_data, dict)\n",
    "        self.assertIn('authors', affiliations_data)\n",
    "        self.assertIn('institutions', affiliations_data)\n",
    "\n",
    "class TestEntityExtraction(unittest.TestCase):\n",
    "    def test_extracted_authors(self):\n",
    "        self.assertGreater(len(extracted_authors), 0)\n",
    "        for author in extracted_authors:\n",
    "            self.assertIn('name', author)\n",
    "            self.assertIn('paper_ids', author)\n",
    "    \n",
    "    def test_extracted_institutions(self):\n",
    "        self.assertGreater(len(extracted_institutions), 0)\n",
    "    \n",
    "    def test_extracted_topics(self):\n",
    "        self.assertIsInstance(extracted_topics, dict)\n",
    "\n",
    "class TestCitationNetwork(unittest.TestCase):\n",
    "    def test_citation_graph(self):\n",
    "        self.assertGreater(len(citation_graph), 0)\n",
    "    \n",
    "    def test_pagerank_sum(self):\n",
    "        self.assertAlmostEqual(sum(pagerank_scores.values()), 1.0, delta=0.01)\n",
    "    \n",
    "    def test_orphan_citations(self):\n",
    "        self.assertGreater(len(orphan_citations), 0)\n",
    "    \n",
    "    def test_self_citations(self):\n",
    "        self.assertGreater(len(self_citations), 0)\n",
    "\n",
    "class TestValidation(unittest.TestCase):\n",
    "    def test_all_validations_pass(self):\n",
    "        failed = [k for k, v in validation_results.items() if not v]\n",
    "        self.assertEqual(len(failed), 0, f\"Failed: {failed}\")\n",
    "\n",
    "class TestFinalReport(unittest.TestCase):\n",
    "    def test_report_structure(self):\n",
    "        self.assertIn('metadata', final_report)\n",
    "        self.assertIn('entity_extraction', final_report)\n",
    "        self.assertIn('citation_analysis', final_report)\n",
    "        self.assertIn('validation_summary', final_report)\n",
    "    \n",
    "    def test_all_checks_passed(self):\n",
    "        self.assertTrue(final_report['validation_summary']['all_checks_passed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all unit tests\n",
    "def run_tests():\n",
    "    loader = unittest.TestLoader()\n",
    "    suite = unittest.TestSuite()\n",
    "    \n",
    "    suite.addTests(loader.loadTestsFromTestCase(TestDataLoading))\n",
    "    suite.addTests(loader.loadTestsFromTestCase(TestEntityExtraction))\n",
    "    suite.addTests(loader.loadTestsFromTestCase(TestCitationNetwork))\n",
    "    suite.addTests(loader.loadTestsFromTestCase(TestValidation))\n",
    "    suite.addTests(loader.loadTestsFromTestCase(TestFinalReport))\n",
    "    \n",
    "    runner = unittest.TextTestRunner(verbosity=2)\n",
    "    result = runner.run(suite)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Tests run: {result.testsRun}\")\n",
    "    print(f\"Failures: {len(result.failures)}\")\n",
    "    print(f\"Errors: {len(result.errors)}\")\n",
    "    print(f\"Success: {result.wasSuccessful()}\")\n",
    "    return result\n",
    "\n",
    "test_result = run_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"GOLDEN SOLUTION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nPapers Analyzed: {len(papers_df)}\")\n",
    "print(f\"Citations Processed: {len(citations_df)}\")\n",
    "print(f\"\\nEntity Resolution:\")\n",
    "print(f\"  Authors: {summary_stats['unique_authors_raw']} raw -> {resolved_author_count} resolved\")\n",
    "print(f\"  Institutions: {summary_stats['unique_institutions_raw']} raw -> {resolved_institution_count} resolved\")\n",
    "print(f\"\\nCitation Network:\")\n",
    "print(f\"  Orphan citations: {len(orphan_citations)}\")\n",
    "print(f\"  Self citations: {len(self_citations)}\")\n",
    "print(f\"  PageRank sum: {sum(pagerank_scores.values()):.4f}\")\n",
    "print(f\"\\nTests: {test_result.testsRun} run, {len(test_result.failures)} failures, {len(test_result.errors)} errors\")\n",
    "\n",
    "if test_result.wasSuccessful() and all(validation_results.values()):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"✓ GOLDEN SOLUTION PASSED ALL TESTS!\")\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"✗ SOME TESTS FAILED\")\n",
    "    print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
